# train_keypoint_classifier.py
import os
import csv
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# ================== é…ç½®å‚æ•° ==================
CSV_PATH = "CSV/main_csv/main_data/keypoint.csv"          # CSV æ•°æ®è·¯å¾„
MODEL_SAVE_PATH = "test_keypoint_data/run/model/keypoint_classifier.tflite"  # TFLite ä¿å­˜è·¯å¾„
BEST_MODEL_PATH = "test_keypoint_data/run/model/best_model.h5"      # Keras ä¿å­˜è·¯å¾„
CURVE_SAVE_PATH = "test_keypoint_data/run/img/training_curve.png" # è®­ç»ƒæ›²çº¿ä¿å­˜è·¯å¾„
EPOCHS = 500
BATCH_SIZE = 16
INPUT_DIM = 42                  # 21 ä¸ªå…³é”®ç‚¹ * 2
VALIDATION_SPLIT = 0.2
RANDOM_STATE = 42
LEARNING_RATE = 0.001
DROPOUT_RATE = 0.3              # é˜²æ­¢è¿‡æ‹Ÿåˆ
EARLY_STOPPING_MIN_DELTA = 1e-4 # loss å‡å°‘å¹…åº¦ä½äºæ­¤å€¼è§†ä¸ºæ— æå‡
EARLY_STOPPING_PATIENCE = 20    # loss æ— æ”¹å–„è¿ç»­å¤šå°‘è½®åœæ­¢
ENABLE_EARLY_STOPPING = True    # æ˜¯å¦å¯ç”¨æ—©åœ
# ============================================

# ---------------- æ•°æ®è¯»å– ----------------
def load_data(csv_path):
    X, y = [], []
    with open(csv_path, "r") as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) != INPUT_DIM + 1:
                continue
            y.append(int(float(row[0])))
            X.append([float(x) for x in row[1:]])
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.int32)
    return X, y

# ---------------- æ¨¡å‹å®šä¹‰ ----------------
def build_model(input_dim, num_classes):
    model = keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(256, activation='relu'),
        keras.layers.Dropout(DROPOUT_RATE),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(DROPOUT_RATE),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(num_classes, activation='softmax')
    ])
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# ---------------- è‡ªå®šä¹‰å›è°ƒ ----------------
class TFLiteCheckpoint(keras.callbacks.Callback):
    """åœ¨ä¿å­˜æœ€ä½³ Keras æ¨¡å‹çš„åŒæ—¶å¯¼å‡º TFLite æ¨¡å‹"""
    def __init__(self, h5_path, tflite_path, monitor='val_loss'):
        super().__init__()
        self.h5_path = h5_path
        self.tflite_path = tflite_path
        self.monitor = monitor
        self.best = np.Inf

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        if current is None:
            return
        if current < self.best:
            self.best = current
            # ä¿å­˜ Keras æ¨¡å‹
            self.model.save(self.h5_path)
            print(f"âœ… Epoch {epoch+1}: val_loss improved, saved Keras model to {self.h5_path}")
            # å¯¼å‡º TFLite
            converter = tf.lite.TFLiteConverter.from_keras_model(self.model)
            tflite_model = converter.convert()
            with open(self.tflite_path, "wb") as f:
                f.write(tflite_model)
            print(f"âœ… åŒæ­¥ä¿å­˜ TFLite æ¨¡å‹è‡³ {self.tflite_path}")

# ---------------- ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ----------------
def plot_training_curve(history, save_path):
    plt.figure(figsize=(10,5))
    # Loss
    plt.subplot(1,2,1)
    plt.plot(history.history['loss'], label='train_loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    # Accuracy
    plt.subplot(1,2,2)
    plt.plot(history.history['accuracy'], label='train_acc')
    plt.plot(history.history['val_accuracy'], label='val_acc')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.tight_layout()
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path)
    plt.close()
    print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³ {save_path}")

# ---------------- ä¸»å‡½æ•° ----------------
def main():
    X, y = load_data(CSV_PATH)
    if len(X) == 0:
        print("âŒ æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ CSV")
        return

    NUM_CLASSES = len(np.unique(y))
    print(f"æ£€æµ‹åˆ°æ‰‹åŠ¿ç±»åˆ«æ•°é‡: {NUM_CLASSES}")
    print("æ ·æœ¬æ•°é‡:", len(X))
    print("X shape:", X.shape, "y shape:", y.shape)

    model = build_model(INPUT_DIM, NUM_CLASSES)
    model.summary()

    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=VALIDATION_SPLIT, random_state=RANDOM_STATE, stratify=y
    )

    # ---------------- å›è°ƒ ----------------
    callbacks = [TFLiteCheckpoint(BEST_MODEL_PATH, MODEL_SAVE_PATH, monitor='val_loss')]
    if ENABLE_EARLY_STOPPING:
        earlystop_cb = keras.callbacks.EarlyStopping(
            monitor='val_loss', min_delta=EARLY_STOPPING_MIN_DELTA,
            patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True, verbose=1
        )
        callbacks.append(earlystop_cb)

    print("\nè®­ç»ƒå¼€å§‹ï¼ŒæŒ‰ Ctrl+C å¯ä¸­æ–­ï¼Œä¹‹åå¯é€‰æ‹©ç»§ç»­æˆ–ç»“æŸ\n")

    try:
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            shuffle=True,
            callbacks=callbacks
        )
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒä¸­æ–­ã€‚")
        cont = input("è¾“å…¥ 'y' ç»§ç»­è®­ç»ƒï¼Œå…¶ä»–é”®ç»“æŸ: ").strip().lower()
        if cont == 'y':
            remaining_epochs = EPOCHS - len(model.history.history['loss'])
            print(f"ç»§ç»­è®­ç»ƒ {remaining_epochs} è½®...")
            history = model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=remaining_epochs,
                batch_size=BATCH_SIZE,
                shuffle=True,
                callbacks=callbacks
            )
        else:
            print("è®­ç»ƒç»“æŸï¼Œä½¿ç”¨å½“å‰æ¨¡å‹æˆ–æœ€ä½³æ¨¡å‹ã€‚")

    # ---------------- å¯¼å‡ºæœ€ç»ˆ TFLite ----------------
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)
    if os.path.exists(BEST_MODEL_PATH):
        model = keras.models.load_model(BEST_MODEL_PATH)

    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open(MODEL_SAVE_PATH, "wb") as f:
        f.write(tflite_model)
    print(f"\nâœ… TFLite æ¨¡å‹å·²ä¿å­˜è‡³ {MODEL_SAVE_PATH}")
    print(f"ğŸ“‚ Keras æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨ {BEST_MODEL_PATH}")

    # ---------------- ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ----------------
    plot_training_curve(history, CURVE_SAVE_PATH)

if __name__ == "__main__":
    main()

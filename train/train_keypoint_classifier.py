# train_keypoint_classifier.py
import os
import csv
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tqdm.keras import TqdmCallback  # è¿›åº¦æ¡

# ================== é…ç½®å‚æ•° ==================
CSV_PATH = "CSV/main_csv/main_data/keypoint.csv"          # CSV æ•°æ®è·¯å¾„
BEST_MODEL_SAVE_PATH = "test_keypoint_data/run/model/best_keypoint_classifier.tflite"  # TFLite ä¿å­˜è·¯å¾„
LAST_MODEL_SAVE_PATH = "test_keypoint_data/run/model/last_keypoint_classifier.tflite"  # TFLite ä¿å­˜è·¯å¾„

BEST_MODEL_PATH = "test_keypoint_data/run/model/best_model.h5"      # Keras ä¿å­˜è·¯å¾„
LAST_MODEL_PATH = "test_keypoint_data/run/model/last_model.h5"      # æœ€åä¸€è½®æ¨¡å‹
CURVE_SAVE_PATH = "test_keypoint_data/run/img/training_curve.png"   # è®­ç»ƒæ›²çº¿ä¿å­˜è·¯å¾„

EPOCHS = 50
BATCH_SIZE = 16
INPUT_DIM = 42                  # 21 ä¸ªå…³é”®ç‚¹ * 2
VALIDATION_SPLIT = 0.2
RANDOM_STATE = 42
LEARNING_RATE = 0.001
DROPOUT_RATE = 0.3
SAVE_EVERY_N_EPOCHS = 10        # æ¯éš”å¤šå°‘è½®ä¿å­˜ä¸€æ¬¡æ¨¡å‹

# ============================================

# ---------------- æ•°æ®è¯»å– ----------------
def load_data(csv_path):
    X, y = [], []
    with open(csv_path, "r") as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) != INPUT_DIM + 1:
                continue
            y.append(int(float(row[0])))
            X.append([float(x) for x in row[1:]])
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.int32)
    return X, y

# ---------------- æ¨¡å‹å®šä¹‰ ----------------
def build_model(input_dim, num_classes):
    model = keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(256, activation='relu'),
        keras.layers.Dropout(DROPOUT_RATE),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(DROPOUT_RATE),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(num_classes, activation='softmax')
    ])
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# ---------------- è‡ªå®šä¹‰å›è°ƒ ----------------
class PeriodicCheckpoint(keras.callbacks.Callback):
    """æ¯éš” N è½®ä¿å­˜æœ€ä½³æ¨¡å‹å’Œæœ€åæ¨¡å‹"""
    def __init__(self, save_every_n_epochs, best_h5_path, last_h5_path, monitor='val_loss'):
        super().__init__()
        self.save_every_n_epochs = save_every_n_epochs
        self.best_h5_path = best_h5_path
        self.last_h5_path = last_h5_path
        self.monitor = monitor
        self.best_val = np.Inf

    def on_epoch_end(self, epoch, logs=None):
        current_val = logs.get(self.monitor)
        if current_val is None:
            return

        # æ›´æ–°æœ€ä½³æ¨¡å‹
        if current_val < self.best_val:
            self.best_val = current_val
            os.makedirs(os.path.dirname(self.best_h5_path), exist_ok=True)
            self.model.save(self.best_h5_path)
            print(f"\nâœ… Epoch {epoch+1}: val_loss æ”¹è¿›ï¼Œä¿å­˜æœ€ä½³æ¨¡å‹è‡³ {self.best_h5_path}")

        # æ¯éš”å›ºå®šè½®ä¿å­˜ last æ¨¡å‹
        if (epoch + 1) % self.save_every_n_epochs == 0:
            os.makedirs(os.path.dirname(self.last_h5_path), exist_ok=True)
            self.model.save(self.last_h5_path)
            print(f"ğŸ’¾ Epoch {epoch+1}: æ¯ {self.save_every_n_epochs} è½®ä¿å­˜ last æ¨¡å‹è‡³ {self.last_h5_path}")

# ---------------- h5 è½¬ tflite ----------------
def convert_h5_to_tflite(h5_path, tflite_path):
    if not os.path.exists(h5_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ {h5_path} ä¸å­˜åœ¨")
        return
    model = tf.keras.models.load_model(h5_path)
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    os.makedirs(os.path.dirname(tflite_path), exist_ok=True)
    with open(tflite_path, "wb") as f:
        f.write(tflite_model)
    print(f"âœ… å·²å°† {h5_path} è½¬æ¢ä¸º TFLite å¹¶ä¿å­˜è‡³ {tflite_path}")

# ---------------- ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ----------------
def plot_training_curve(history, save_path):
    plt.figure(figsize=(10,5))
    plt.subplot(1,2,1)
    plt.plot(history.history['loss'], label='train_loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.subplot(1,2,2)
    plt.plot(history.history['accuracy'], label='train_acc')
    plt.plot(history.history['val_accuracy'], label='val_acc')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.tight_layout()
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path)
    plt.close()
    print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³ {save_path}")

# ---------------- ä¸»å‡½æ•° ----------------
def main():
    X, y = load_data(CSV_PATH)
    if len(X) == 0:
        print("âŒ æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ CSV")
        return

    NUM_CLASSES = len(np.unique(y))
    print(f"æ£€æµ‹åˆ°æ‰‹åŠ¿ç±»åˆ«æ•°é‡: {NUM_CLASSES}")
    print("æ ·æœ¬æ•°é‡:", len(X))
    print("X shape:", X.shape, "y shape:", y.shape)

    model = build_model(INPUT_DIM, NUM_CLASSES)
    model.summary()

    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=VALIDATION_SPLIT, random_state=RANDOM_STATE, stratify=y
    )

    callbacks = [PeriodicCheckpoint(
        save_every_n_epochs=SAVE_EVERY_N_EPOCHS,
        best_h5_path=BEST_MODEL_PATH,
        last_h5_path=LAST_MODEL_PATH
    ), TqdmCallback(verbose=1)]

    print("\nè®­ç»ƒå¼€å§‹ï¼ŒæŒ‰ Ctrl+C å¯ä¸­æ–­\n")

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        shuffle=True,
        callbacks=callbacks,
        verbose=0  # tqdm æ˜¾ç¤ºè¿›åº¦æ¡
    )

    # ---------------- æœ€åä¸€è½®ä¿å­˜ last æ¨¡å‹ ----------------
    os.makedirs(os.path.dirname(LAST_MODEL_PATH), exist_ok=True)
    model.save(LAST_MODEL_PATH)
    print(f"\nğŸ“‚ æœ€åä¸€è½®æ¨¡å‹å·²ä¿å­˜è‡³ {LAST_MODEL_PATH}")

    # ---------------- è½¬ TFLite ----------------
    convert_h5_to_tflite(BEST_MODEL_PATH, BEST_MODEL_SAVE_PATH)
    convert_h5_to_tflite(LAST_MODEL_PATH, LAST_MODEL_SAVE_PATH)

    # ---------------- ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ----------------
    plot_training_curve(history, CURVE_SAVE_PATH)

if __name__ == "__main__":
    main()
